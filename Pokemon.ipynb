{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pokemon.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yzFEOTOEa1kilB5kT5rNCS1Qrqy_Duzg",
      "authorship_tag": "ABX9TyN2V91mlPZB+pXTq3xOGkHv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Developer-Yee/2021-1-Data-Science/blob/main/Pokemon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr3UFhRgJdDe"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VasUgK6dUOWc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets.folder import pil_loader\n",
        "from matplotlib.pyplot import imshow\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBGcZZribFDP"
      },
      "source": [
        "## Load Zip File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwHvJUaRTOoH"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "# train.zip\n",
        "output_unzip = zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/train.zip', 'r')\n",
        "output_unzip.extractall('/content/')\n",
        "output_unzip.close()\n",
        "\n",
        "# test.zip\n",
        "output_unzip = zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/test.zip', 'r')\n",
        "output_unzip.extractall('/content/')\n",
        "output_unzip.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R89nDGkdKX6S"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/train.zip' -d '/content'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw8jPcA6cjcx"
      },
      "source": [
        "## Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNCIL9VtUkau"
      },
      "source": [
        "pokemon = []\n",
        "\n",
        "for dirname, _, filenames in os.walk('/content/train'):\n",
        "    pokemon.append(dirname.replace('/content/train/', ''))\n",
        "\n",
        "pokemon.pop(0)\n",
        "pokemon.sort()\n",
        "\n",
        "# poketmon list\n",
        "print(pokemon)   \n",
        "      \n",
        "# poketmon length \n",
        "print(len(pokemon))     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h44MFI6DdWKs"
      },
      "source": [
        "## Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSKn5su1DOa0"
      },
      "source": [
        "test_pokemon = []\n",
        "\n",
        "for dirname, _, filenames in os.walk('/content/test/'):\n",
        "    test_pokemon.append(filenames)\n",
        "\n",
        "print(test_pokemon)\n",
        "print(len(test_pokemon[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZQAnIDb36t2"
      },
      "source": [
        "## Custom Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFsVni9xQYEb"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm9ZEbw55NN9"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path, transform, data_type = 'train'):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        \n",
        "        self.path = path\n",
        "        self.transform = transform\n",
        "        self.data_type = data_type\n",
        "        self.image_list = self.get_img_list()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(self.image_list[index]).convert('RGB')\n",
        "        image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "    def get_img_list(self):\n",
        "        if(self.data_type == 'train'):\n",
        "            pass\n",
        "        elif(self.data_type == 'val'):\n",
        "            pass\n",
        "        elif(self.data_type == 'test'):\n",
        "            return glob(self.path + '/*')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMY7demdVSd1"
      },
      "source": [
        "trans = torchvision.transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# Train data\n",
        "train_data = torchvision.datasets.ImageFolder(root='/content/train', transform=trans)\n",
        "print(len(train_data))\n",
        "print(train_data)\n",
        "data_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "trans = torchvision.transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Test data\n",
        "test_data = CustomDataset('/content/test', trans, data_type='test')\n",
        "test_set = DataLoader(dataset=test_data, batch_size=1)\n",
        "print(len(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPlzn0ypd7U8"
      },
      "source": [
        "## VGG_A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MJ8bCqpQSVZ"
      },
      "source": [
        "class VGG_A(nn.Module):\n",
        "    def __init__(self, num_classes: int = 501, init_weights: bool = True):\n",
        "        super(VGG_A, self).__init__()\n",
        "        self.convnet = nn.Sequential(\n",
        "            # Input Channel (RGB: 3)\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 224 -> 112\n",
        "            \n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 112 -> 56\n",
        "            \n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 56 -> 28\n",
        "\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 28 -> 14\n",
        "\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 14 -> 7\n",
        "        )\n",
        "\n",
        "        self.fclayer = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x:torch.Tensor):\n",
        "        out = self.convnet(x)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fclayer(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZh1KvLEJbfG"
      },
      "source": [
        "vgg_a = VGG_A().to(device)\n",
        "test_input = (torch.Tensor(8, 3, 256, 256)).to(device)\n",
        "test_out = vgg_a(test_input)\n",
        "print(test_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZlrSE38WMRd"
      },
      "source": [
        "## RESNET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_Y5UEOg1Bad"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cqZreKq1eCt"
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bShkD5Li1hBU"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x) # 3x3 stride = 2\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out) # 3x3 stride = 1\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F6MOKQv1jA6"
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = conv1x1(inplanes, planes) #conv1x1(64,64)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes, stride)#conv3x3(64,64)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = conv1x1(planes, planes * self.expansion) #conv1x1(64,256)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x) # 1x1 stride = 1\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out) # 3x3 stride = stride \n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out) # 1x1 stride = 1\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBL7y4Io1ni-"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    # model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs) #resnet 50 \n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
        "        super(ResNet, self).__init__()\n",
        "        \n",
        "        self.inplanes = 64\n",
        "\n",
        "        # input [3x256x256]\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        self.layer1 = self._make_layer(block, 64, layers[0]'''3''')\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1]'''4''', stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2]'''6''', stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3]'''3''', stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "    \n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        \n",
        "        downsample = None\n",
        "        \n",
        "        if stride != 1 or self.inplanes != planes * block.expansion: \n",
        "            \n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride), #conv1x1(256, 512, 2)\n",
        "                nn.BatchNorm2d(planes * block.expansion), #batchnrom2d(512)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        \n",
        "        self.inplanes = planes * block.expansion #self.inplanes = 128 * 4\n",
        "        \n",
        "        for _ in range(1, blocks): \n",
        "            layers.append(block(self.inplanes, planes)) # * 3\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TjFe5S41oJP"
      },
      "source": [
        "def resnet18(pretrained=False, **kwargs):\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs) #=> 2*(2+2+2+2) +1(conv1) +1(fc)  = 16 +2 =resnet 18\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg7nDNa21qpZ"
      },
      "source": [
        "def resnet50(pretrained=False, **kwargs):\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs) #=> 3*(3+4+6+3) +(conv1) +1(fc) = 48 +2 = 50\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_MIMljR1r8l"
      },
      "source": [
        "def resnet152(pretrained=False, **kwargs):\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs) # 3*(3+8+36+3) +2 = 150+2 = resnet152    \n",
        "    return mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6C6macJ1wSE"
      },
      "source": [
        "import torchvision.models.resnet as resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di-WYdYP1xDi"
      },
      "source": [
        "res = resnet.resnet50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPxAHdDe11jM"
      },
      "source": [
        "res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr84UDr-Dl4Y"
      },
      "source": [
        "num_classes = 151\n",
        "test_input = (torch.Tensor(8, 3, 256, 256)).to(device)\n",
        "num_ftrs = res.fc.in_features\n",
        "res.fc = nn.Linear(num_ftrs, num_classes)\n",
        "res.to(device)\n",
        "test_out = res(test_input)\n",
        "print(test_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAjhXMHoet1L"
      },
      "source": [
        "## Optimizer && Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSBnC1IlKjap"
      },
      "source": [
        "optimizer = optim.Adam(res.parameters(), lr=0.0001)\n",
        "loss_func = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPVsRjr-eyy1"
      },
      "source": [
        "## Train 정확도 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOsnXGRAK3za"
      },
      "source": [
        "pre_accuracy = 0.0\n",
        "total_batch = len(data_loader)\n",
        "epochs = 30\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_cost = 0.0\n",
        "    for num, data in enumerate(data_loader):\n",
        "        imgs, labels = data\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = res(imgs)\n",
        "        loss = loss_func(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += loss / total_batch\n",
        "\n",
        "        correct_prediction = torch.argmax(out, 1) == labels\n",
        "    \n",
        "    accuracy = correct_prediction.float().mean()\n",
        "\n",
        "    if(pre_accuracy < accuracy):\n",
        "        pre_accuracy = accuracy\n",
        "        torch.save(res.state_dict(), '/content/drive/MyDrive/Colab Notebooks/train_data/res50.pth')\n",
        "\n",
        "    print('[Epoch:{}] cost = {} accuracy = {}'.format(epoch+1, avg_cost, accuracy))\n",
        "\n",
        "print('Learning Finished!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1wqqWOlenzL"
      },
      "source": [
        "## 저장한 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3LkEiqRMGVI"
      },
      "source": [
        "new_net = VGG_A().to(device)\n",
        "new_net.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/train_data/vgg_a_p05.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db3In36meI3u"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLJ3zjuoNO32"
      },
      "source": [
        "l = []\n",
        "\n",
        "print(len(test_set))\n",
        "with torch.no_grad():\n",
        "    for num, data in enumerate(test_set):\n",
        "\n",
        "        imgs = data\n",
        "        imgs = imgs.to(device)\n",
        "        # label = label.to(device)\n",
        "\n",
        "        prediction = vgg_a(imgs)\n",
        "\n",
        "        index = torch.argmax(prediction, 1).tolist()[0]\n",
        "        l.append([pokemon[index], index])\n",
        "\n",
        "        # correct_prediction = torch.argmax(prediction, 1) == label\n",
        "        \n",
        "        # accuracy = correct_prediction.float().mean()\n",
        "        # print('Accuracy', accuracy.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkruGWPFeT25"
      },
      "source": [
        "## To CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAK_VWHIYmov"
      },
      "source": [
        "df = pd.DataFrame(l)\n",
        "print(df)\n",
        "df.to_csv('/content/test.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjcPLRGPegoY"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}